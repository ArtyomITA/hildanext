# HILDA

> **Pushing discrete diffusion language models past what autoregressive transformers can do â€” one ablation at a time.**

HILDA is a research architecture for advancing the state of the art in discrete diffusion language models. The goal is not to fine-tune existing models: it is to explore and validate a full stack of architectural decisions â€” from how an AR model is converted into a dLLM, to how it reasons, to how structural attention supervision and inference acceleration interact â€” in order to build architectures that are **potentially competitive with or superior to AR baselines of the same size**.

Everything is designed to be modular, ablatable, and reproducible on a single consumer GPU.

---

## The Architecture

HILDA is built around four interlocking design pillars.

### 1 â€” Editable Diffusion Core (LLaDA 2.1 style)

Classical masked diffusion only knows one move: `[MASK] â†’ token`.
HILDA's core adds a second move: `token â†’ token` (T2T editing).

This means the model can **revisit and correct already-placed tokens** during decoding, not just fill in blanks. The two operations are interleaved via configurable thresholds:

```
Î“t  unmasking  â€” MASK â†’ token  when p > Ï„_mask   (commit)
Î”t  editing    â€” token â†’ token when p > Ï„_edit   (correct)
```

Two runtime presets expose the speed/quality knob explicitly:

| Preset               | Behaviour                                                 |
| -------------------- | --------------------------------------------------------- |
| `S_MODE` (quality) | low Ï„_mask, more correction passes â€” best output        |
| `Q_MODE` (speed)   | high Ï„_mask, conservative drafting â€” fastest throughput |

Training objective is a mixture of M2T and T2T losses with doc-level attention masking built from `doc_ids`, preventing cross-document attention leakage.

### 2 â€” WSD Conversion Schedule

HILDA converts an existing AR model rather than training from scratch via **Warmup-Stable-Decay**:

```
Warmup  â†’ block size grows 1 â†’ N  (AR treated as BDLM, block size = 1)
Stable  â†’ full-sequence MDLM regime (stabilise ELBO and diffusion dynamics)
Decay   â†’ shrink block, consolidate editable representation
```

CPT objective: M2T loss on masked positions + T2T loss on noised observed positions. No training from scratch, no architecture surgery.

### 3 â€” Reasoning Alignment via RL

After SFT, HILDA targets **verifiable reasoning tasks** (math, code) through RL objectives specifically designed for the dLLM setting, where token-level PPO is ill-posed due to the absence of a natural likelihood factorisation.

The default objective is **ESPO**: an ELBO sequence-level proxy with ratio-stabilised KL. Rather than committing to one estimator, HILDA treats the RL objective itself as an ablation axis â€” comparing ESPO, wd1, and AGRPO under the same compute budget to find what actually moves reasoning quality on small models.

| Method | Role |
|---|---|
| **ESPO** | Principled ELBO-level baseline; ratio-stabilised KL |
| **wd1 / wd1++** | Ratio-free alternative; lower variance, step-wise variant |
| **AGRPO** | MC-faithful policy gradient designed for dLLM step structure |
| **STP** | Spatio-temporal pruning â€” fewer denoising steps per rollout |
| **LENS** | Filters instruction-interfering tokens before rollout |
| **RÂ³L** | Reflect-then-retry credit assignment for multi-step reasoning |

### 4 â€” Inference, Attention & Structural Supervision

The fourth pillar covers everything that happens **after the model is trained**: how attention is structured during generation, how computation is reused across denoising steps, and how decoding can be made faster or smarter without retraining.

**Structural attention (C2DLM)** â€” applied preferentially on T2T correction passes:
- Concept-level causal graph constrains which heads can attend to which positions
- Supervised attention mask enforces causal consistency during reasoning chains
- V-aware re-attention re-weights value vectors by concept role

**Inference acceleration stack:**
- **RCD** â€” recycles hidden states discarded by remasking as residual context for the next step
- **D2F / Fast-dLLM v2** â€” hierarchical KV caching (block + sub-block), ~1B token adaptation cost
- **CARD** â€” confidence-adaptive token generation: more tokens per step when top-1 confidence is high
- **Order-Token Search** â€” decoding-time search over generation order and token trajectories; zero training change
- **KVzap / KVpress** â€” adaptive KV cache pruning, 2â€“4Ã— compression

---

## System Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Pretrained AR  (Qwen3-0.6B / 1.7B-Base, Apache-2.0)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   Stage 0 â€” CPT / WSD   â”‚  Dolma v1.6 + TinyStories
              â”‚   M2T + T2T objective   â”‚  doc-level attention mask
              â”‚   Warmupâ†’Stableâ†’Decay   â”‚  packed shards w/ doc_ids
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   Stage 1 â€” SFT         â”‚  response-focused masking
              â”‚   mixture M2T + T2T     â”‚  multi-turn (2Ã— T2T/step)
              â”‚   [+ C2DLM FULL]        â”‚  C2DLM on correction passes
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   Stage 2 â€” RL          â”‚  ESPO (ELBO seq-level)
              â”‚   verifiable rewards    â”‚  GSM8K / HumanEval
              â”‚   [+ AGRPO / wd1 FULL]  â”‚  STP, LENS, RÂ³L
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   Stage 3 â€” Serving     â”‚  dInfer â†’ Transformers
              â”‚   threshold-edit loop   â”‚  S_MODE / Q_MODE
              â”‚   REST API              â”‚  /health /generate /jobs/*
              â”‚   [+ RCD / D2F FULL]    â”‚  Order-Token Search, KVzap
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**SAFE profile** â€” everything above the `[FULL]` lines. Stable, reproducible, no custom CUDA extensions.  
**FULL profile** â€” adds advanced RL estimators (AGRPO, wd1, STP, LENS, RÂ³L), structural attention supervision (C2DLM), and inference acceleration (RCD, D2F, CARD, Order-Token Search, KVzap). Each layer is an independent ablation.

---

## Tech Stack

| Layer            | Tool                                                                           |
| ---------------- | ------------------------------------------------------------------------------ |
| Language         | Python 3.11                                                                    |
| Deep learning    | PyTorch â‰¥ 2.4 + CUDA 12.1                                                     |
| Model loading    | HuggingFace Transformers â‰¥ 4.51                                               |
| Inference engine | [dInfer](https://github.com/inclusionAI/dInfer) (guarded) + Transformers fallback |
| API server       | FastAPI + Uvicorn                                                              |
| Quantisation     | bitsandbytes â€” QLoRA/NF4 (cc â‰¥ 6.0), 8-bit optimiser                         |
| Data             | HuggingFace Datasets + Dolma v1.6 sample                                       |
| Config           | JSON, fully config-driven                                                      |
| Packaging        | `pyproject.toml` / setuptools                                                |
| CLI              | `hildanext` (argparse)                                                       |

---

## Repository Layout

```
hildanext/
â”œâ”€â”€ backend/src/hildanext/
â”‚   â”œâ”€â”€ cli.py              # CLI entrypoint
â”‚   â”œâ”€â”€ api.py              # FastAPI /health /generate /jobs/*
â”‚   â”œâ”€â”€ wsd_stage0.py       # WSD conversion schedule
â”‚   â”œâ”€â”€ diffusion.py        # M2T + T2T forward / corruption
â”‚   â”œâ”€â”€ masks.py            # doc-level attention mask builder
â”‚   â”œâ”€â”€ training.py         # SFT trainer loop
â”‚   â”œâ”€â”€ inference.py        # threshold-edit decode (S/Q mode)
â”‚   â”œâ”€â”€ ar.py               # AR baseline wrapper
â”‚   â”œâ”€â”€ datasets.py         # Dolma + TinyStories loader
â”‚   â”œâ”€â”€ tokenization.py     # packing with doc_ids
â”‚   â””â”€â”€ recipe.py           # end-to-end run orchestrator
â”œâ”€â”€ test/                   # 25+ unit + smoke tests
â”œâ”€â”€ docs/                   # architecture references
â”œâ”€â”€ runs/configs/           # JSON run configs
â”œâ”€â”€ DESIGN.md               # SAFE design decisions log
â””â”€â”€ VERSIONS.md             # pinned commits and deps
```

---

## Quests / Roadmap

### Stage 0 â€” CPT / WSD Conversion âœ…

- [X] WSD schedule (warmup / stable / decay)
- [X] M2T + T2T training objective
- [X] Doc-level attention masking from `doc_ids`
- [X] Dolma v1.6 + TinyStories data pipeline
- [X] Tokenisation and packing with doc boundary tracking
- [X] Special token registration for `[MASK]` without embedding remap
- [X] ELBO logging per training step

### Stage 1 â€” SFT âœ…

- [X] Response-focused M2T+T2T mixture loss
- [X] Multi-turn forward (two T2T noising passes per step)
- [X] Multi-turn conversation format with turn boundary masking
- [X] Train/eval split with held-out SFT shard
- [X] SFT smoke test (dummy batch, loss finite check)

### Stage 2 â€” Inference & Serving âœ…

- [X] Threshold-edit decode loop (Î“t + Î”t)
- [X] `S_MODE` / `Q_MODE` presets
- [X] dInfer adapter + Transformers fallback
- [X] FastAPI REST server with `/health`, `/generate`, `/jobs/*`
- [X] CLI `hildanext generate`
- [X] Per-step decode tracing (mask ratio, edit count, throughput estimate)
- [X] Inference smoke test against dummy model (no weights required)

### Stage 3 â€” RL Reasoning ðŸ”¬

Each component is ablated independently before stacking. Benchmarks run once at the end of each sub-phase against the SFT baseline, not after every individual item.

**3a â€” Reward infrastructure**

- [ ] Verifiable reward runner: GSM8K exact-match scorer, HumanEval pass@k executor
- [ ] Rollout sampler under current dLLM policy (S_MODE / Q_MODE), with hard budget cap per step (8 GB constraint)
- [ ] Reward normalisation and advantage estimation utilities
- [ ] Record SFT-only baseline numbers (GSM8K, HumanEval) before touching any RL objective

**3b â€” RL objective comparison (ESPO / wd1 / AGRPO)**Three objectives, one controlled comparison run on the same GSM8K subset and compute budget:

- [ ] **ESPO**: ELBO sequence-level proxy, ratio-stabilised KL (Î² sweep: 0.01 / 0.05 / 0.1)
- [ ] **wd1 / wd1++**: ratio-free weighted log-likelihood, step-wise variant
- [ ] **AGRPO**: MC rollout estimator step-aware policy gradient (K samples: 4 / 8 / 16)
- [ ] Output: three-way comparison table â€” accuracy Î´, gradient variance, VRAM peak, training stability

**3c â€” Efficiency plugins for small-model rollouts**

- [ ] **STP**: spatio-temporal pruning of redundant denoising steps â€” same accuracy, fewer steps
- [ ] **LENS**: filter instruction-interfering tokens before rollout â€” higher success rate, lower variance across prompt phrasings
- [ ] **RÂ³L**: reflect-then-retry credit assignment, max 2 retries per step to keep forward-pass count tractable on small models
- [ ] Applied on top of the best objective from 3b; one combined comparison vs 3b-winner baseline

**3d â€” Full evaluation**

- [ ] GSM8K (exact match), MATH-500 subset (directional), HumanEval (pass@1 + pass@10)
- [ ] TinyStories perplexity regression (RL must not break fluency)
- [ ] Final table: SFT â†’ best-RL-objective â†’ best-RL+efficiency-plugins

### Stage 4 â€” FULL Acceleration ðŸ”¬

All components benchmarked against the Stage 2 threshold-edit decode baseline. Shared metrics: tokens/sec, VRAM peak, perplexity Î´, HumanEval pass@1 Î´.

**4a â€” Quality stack: RCD + C2DLM**

- [ ] **RCD**: residual carry-over of remasked hidden states between denoise steps; ELBO audit before/after; ablation on injection weight Î± âˆˆ {0.1, 0.3, 0.5}
- [ ] **C2DLM**: concept-level causal graph, supervised attention mask applied on T2T passes only; V-aware re-attention weighting; ablation T2T-only vs always-on
- [ ] Evaluation: quality stack table â€” SFT â†’ +RCD â†’ +RCD+C2DLM on GSM8K and TinyStories

**4b â€” Speed stack: KV caching + compression + adaptive decoding**

- [ ] **D2F / Fast-dLLM v2**: block-level KV cache (invalidate on T2T edit) + sub-block reuse; integration test for stale-KV correctness under edits
- [ ] **KVzap**: adaptive KV pruning at 2Ã— and 4Ã— ratios; verify no double-pruning with D2F cache
- [ ] **CARD**: variable tokens-per-step when top-1 confidence > gate; Pareto curve vs fixed Q_MODE Ï„_mask=0.5
- [ ] Evaluation: speed stack table â€” baseline â†’ +D2F â†’ +D2F+KVzap â†’ +D2F+KVzap+CARD

**4c â€” Decoding search: Order-Token Search**

- [ ] Search over generation order trajectories; beam B âˆˆ {1, 2, 4} â€” B=1 must reproduce greedy baseline exactly
- [ ] Zero training change; compare vs S_MODE greedy on HumanEval pass@1 and GSM8K; cost/quality table per B

### Hardware / Tooling

- [X] Pascal sm_61 compatible â€” no FlashAttention, no vLLM required
- [X] CPU-only demo mode
- [X] QLoRA / bitsandbytes optional path
- [ ] ONNX export
- [ ] Automated benchmark runner: one command to reproduce all comparison tables

---

## Quick Start

```bash
git clone https://github.com/ArtyomITA/hildanext.git
cd hildanext
python -m venv .venv && .venv\Scripts\activate
pip install -e hildanext/backend

# smoke test (CPU, no model weights needed)
python hildanext/test/run_tests.py

# start API server
hildanext serve --config hildanext/runs/configs/default.json

# generate
hildanext generate --prompt "Once upon a time" --mode S_MODE
```

---

## Hardware Target

Built and tested on a **GTX 1080 (Pascal, sm_61, 8 GB VRAM)** with CUDA 12.1 / PyTorch 2.4.CPU fallback is fully functional. No custom CUDA extensions â€” forward-compatible through Pascal's remaining driver lifetime.

> CUDA 13.0 drops offline compilation for Maxwell/Pascal/Volta. This backend avoids all custom CUDA kernels intentionally.

---

## Vendored Dependencies *(excluded from this repo)*

| Path                        | Repo                                                     | Pinned commit |
| --------------------------- | -------------------------------------------------------- | ------------- |
| `hildanext/vendor/llada`  | [ML-GSAI/LLaDA](https://github.com/ML-GSAI/LLaDA)           | `570f290`   |
| `hildanext/vendor/dinfer` | [inclusionAI/dInfer](https://github.com/inclusionAI/dInfer) | `1ffeb96`   |
| `LLaDA/`                  | ML-GSAI/LLaDA                                            | upstream      |
| `Qwen3-0.6B/`             | [Qwen/Qwen3-0.6B](https://huggingface.co/Qwen/Qwen3-0.6B)   | â€”            |

---

## License

Original code under `hildanext/` â€” MIT.
Vendored repos retain their upstream licenses.
